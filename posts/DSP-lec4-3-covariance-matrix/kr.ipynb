{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "113399a6-d2de-49d6-a5a0-d8a98c54502b",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Covariance Matrix\"\n",
    "description: KAIST Data Science Programming 1 - 4-3. Covariance Matrix에 대한 내용입니다.\n",
    "date: 2023-10-25\n",
    "author: \"Chanseok Kang\"\n",
    "toc: true \n",
    "categories: [Python, KAIST, Statistics]\n",
    "title-block-banner: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcc98f4-54ad-487d-8456-2a565359eea4",
   "metadata": {},
   "source": [
    "## Covariance Matrix\n",
    "\n",
    "두 개의 random variable 간의 Variance를 Matrix 형태로 표현한 것을 **Covariance Matrix** 라고 한다. 일반적으로 두 variable간의 관계를 표현한 것이기 때문에 square matrix 형태를 가지며, symmetric 하면서, positive semi-definite한 성격을 가진다. \n",
    "$$\n",
    "a^T \\Sigma a \\ge 0, \\text{for all }a \\in \\mathbb{R}^n\n",
    "$$\n",
    "\n",
    "> **_NOTE:_** Positive semi-definite 하다는 것은 Matrix가 symmetric하면서, 다음의 성격을 가지는 것을 말한다. $v^T A v \\ge 0 \\text{ for }v \\in \\mathbb{R}^n$\n",
    "\n",
    "그리고 covariance matrix의 구성요소는 다음과 같이 정의된다.\n",
    "\n",
    "$$\n",
    "\\Sigma_{X_i, X_j} = cov[X_i, X_j] = \\mathbb{E}[(X_i - \\mathbb{E}[X_i])(X_j - \\mathbb{E}[X_j])]\n",
    "$$\n",
    "(참고로 위 식은 이전 포스트에서 Covariance에 대한 MLE Solution을 유도하면서 구한 내용이다.)\n",
    "\n",
    "이렇게 대면 대각 성분 (diagnoal value)들은 같은 index에 대해서 평균값을 빼준 것을 제곱한 형태가 되므로 결국 variance라는 것을 알 수 있다. \n",
    "\n",
    "그런데 covariance 값을 위 식을 통해서 구할 수는 있어도, 이 값을 계산하는데 어떠한 normalization이 적용되지 않았기 때문에, 값만 보고 이게 어떤 의미다라는 것을 도출하기가 쉽지 않다. 예를 들어서 covariance가 1이다 라는 정보는 두 random variable 간의 상대적인 변화를 나타내기 때문에 값이 크다, 작다만 가지고 정보량을 얻을 수 없다. 그래서 이 값을 normalization한 후의 결과를 활용하는데, 이를 **(Pearson) Correlation Coefficient**라고 한다.\n",
    "\n",
    "$$\n",
    "\\rho_{X_i, X_j} = \\frac{cov(X_i, X_j)}{\\sigma_{X_i} \\sigma_{X_j}} = (diag(\\Sigma))^{-\\frac{1}{2}} \\Sigma (diag(\\Sigma))^{-\\frac{1}{2}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01138202-3551-4a97-8727-7370d252dc56",
   "metadata": {},
   "source": [
    "## Pearson Correlation\n",
    "\n",
    "그러면 위의 correlation coefficient를 풀어서 정의해보면 아래와 같다.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\rho_{X_i, X_j} = \\frac{cov(X_i, X_j)}{\\sigma_{X_i} \\sigma_{X_j}} &= \\frac{\\mathbb{E}[(X_i - \\mathbb{E}[X_i])(X_j - \\mathbb{E}[X_j])]}{\\sqrt{\\mathbb{E}[(X_i - \\mathbb{E}[X_i])(X_i - \\mathbb{E}[X_i])]}\\sqrt{\\mathbb{E}[(X_j - \\mathbb{E}[X_j])(X_j - \\mathbb{E}[X_j])]}} \\\\\n",
    "&= \\frac{\\mathbb{E}[X_i X_j] - \\mathbb{E}[X_i]\\mathbb{E}[X_j]}{\\sqrt{\\mathbb{E}[X_i^2] - (\\mathbb{E}[X_i])^2} \\sqrt{\\mathbb{E}[X_j^2] - (\\mathbb{E}[X_j])^2}}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926213a7-2710-4ed4-b343-41624e956c50",
   "metadata": {},
   "source": [
    "그러면 이 값이 앞에서 설명한 것처럼 정말로 normalize된 값인지 확인을 해보기 위해서 inequality를 통한 값의 range를 구해본다. 먼저 range를 구하기 전에 variance sum law를 나열해본다.\n",
    "\n",
    "$$\n",
    "Var(x + y) = Var(x) + Var(y) + 2 Cov(x, y)\n",
    "$$\n",
    "\n",
    "여기서 $X / \\sigma_X$ 라는 term으로 위의 variance sum law에 넣어보면 다음과 같은 식을 구할 수 있는데,\n",
    "\n",
    "$$\n",
    "Var(\\frac{X_i}{\\sigma_{X_i}} \\pm \\frac{X_j}{\\sigma_{X_j}}) = Var(\\frac{X_i}{\\sigma_{X_i}}) + Var(\\frac{X_j}{\\sigma_{X_j}}) \\pm 2 Cov (\\frac{X_i}{\\sigma_{X_i}}, \\frac{X_j}{\\sigma_{X_j}})\n",
    "$$\n",
    "\n",
    "위의 값은 Variance의 형태이므로 기본적으로 0보다 큰 값을 가진다. 거기에 각 variable의 $\\sigma$ 는 상수와 같으므로 Variance 밖으로 뺄 수 있는데,\n",
    "\n",
    "$$\n",
    "0 \\le \\frac{1}{\\sigma^2_{X_i}} Var(X_i) + \\frac{1}{\\sigma^2_{X_j}} Var(X_j) \\pm 2 Cov (\\frac{X_i}{\\sigma_{X_i}}, \\frac{X_j}{\\sigma_{X_j}})\n",
    "$$\n",
    "\n",
    "결과적으로 같은 값이기에 1이 된다. 나머지 term을 마저 정리하면,\n",
    "\n",
    "$$ \n",
    "0 \\le 2 + 2 Cov (\\frac{X_i}{\\sigma_{X_i}}, \\frac{X_j}{\\sigma_{X_j}}) = 2 + 2 Corr (X_i, X_j) \\\\\n",
    "-1 \\le \\rho_{X_i, X_j} \\le 1\n",
    "$$\n",
    "\n",
    "라는 결과를 얻을 수 있다. 즉 correlation coefficient는 -1과 1 사이의 값을 가지게 되며, 이 말은 어떤 variable간에 비교하여도 correlation coefficient의 크기에 따라서 값의 상관관계를 대략적으로 알수 있다는 것을 의미하게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50295b5",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
