{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Pearson Correlation\"\n",
    "description: KAIST Data Science Programming 1 - 4-4. Pearson Correlation에 대한 내용입니다.\n",
    "date: 2023-10-31\n",
    "author: \"Chanseok Kang\"\n",
    "toc: true \n",
    "categories: [Python, KAIST, Statistics]\n",
    "title-block-banner: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pearson Correlation and its Geometric Interpretation\n",
    "\n",
    "이전 정리에서 살펴봤던 Pearson Correlation을 가져와보자.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\rho_{X_i, X_j} = \\frac{cov(X_i, X_j)}{\\sigma_{X_i} \\sigma_{X_j}} &= \\frac{\\mathbb{E}[(X_i - \\mathbb{E}[X_i])(X_j - \\mathbb{E}[X_j])]}{\\sqrt{\\mathbb{E}[(X_i - \\mathbb{E}[X_i])(X_i - \\mathbb{E}[X_i])]}\\sqrt{\\mathbb{E}[(X_j - \\mathbb{E}[X_j])(X_j - \\mathbb{E}[X_j])]}} \\\\\n",
    "&= \\frac{\\mathbb{E}[X_i X_j] - \\mathbb{E}[X_i]\\mathbb{E}[X_j]}{\\sqrt{\\mathbb{E}[X_i^2] - (\\mathbb{E}[X_i])^2} \\sqrt{\\mathbb{E}[X_j^2] - (\\mathbb{E}[X_j])^2}}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "이와 비슷한 성격을 띄는 metric 중 하나가 cosine similarity라는 것이 있는데, 다음과 같이 정의된다.\n",
    "\n",
    "$$ \n",
    "cos(\\theta) = \\frac{x_i \\cdot x_j}{\\Vert x_i \\Vert \\Vert x_j \\Vert} = \\frac{\\sum_{d=1}^n x_{i, d} x_{j_d}}{\\sqrt{\\sum_{d=1}^n x_{i, d}^2}\\sqrt{\\sum_{d=1}^n x_{j, d}^2}}\n",
    "$$\n",
    "\n",
    "사실 이 값은 cosine 값이기 때문에 잘 알고 있는 것처럼 -1과 1 사이의 값을 가진다. 여기에서 만약 각 비교하는 변수들의 평균이 0이라고 가정을 해보면 다음과 같이 정리가 된다. (물론 막연하게 평균이 0이라는 조건을 단 것이긴 하지만, 어떤 분포가 있을 때 분포의 평균을 0으로 만드는 것은 단순히 shift를 하면 가능한 것이기에 이와 같은 가정을 둬도 성립하는 것이다.)\n",
    "\n",
    "$$\n",
    "cos(\\theta) = \\frac{\\mathbb{E}[X_i X_j]}{\\sqrt{\\mathbb{E}[X_i^2]}\\sqrt{\\mathbb{E}[X_j]^2}} = \\frac{cov(X_i, X_j)}{\\sigma_{X_i} \\sigma_{X_j}} = \\rho_{X_i, X_j}\n",
    "$$\n",
    "\n",
    "이전 정리에서는 Variance sun law를 사용해서 correlation coefficient의 값의 범위를 증명했었는데, 위와 같은 방법으로도 값의 범주를 찾아볼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Properties of Pearson Correlation\n",
    "\n",
    "Correlation 에는 다음과 같은 몇가지 성질을 가진다.\n",
    "\n",
    "- $\\rho_{X_i, X_i} = 1$ : 동일한 값에 대한 correlation coefficient는 항상 1을 가진다.\n",
    "- $\\rho_{X_i, X_j} = \\rho_{X_j, X_i}$ : Correlation coefficient의 근간이 되는 Covariance matrix 자체가 symmetric 성격을 가지기에 역시 동일한 성격을 가진다.\n",
    "- $Corr(a X_i + b, X_j) = sign(a) Corr(X_i, X_j) \\text{ for any } a, b \\in R$ : shift가 되는 값은 상관없이 scale이 되는 값의 **부호** 만 영향을 미친다.\n",
    "- $-1 \\le \\rho_{X_i, X_j} \\le 1$ : 앞에서 설명\n",
    "- $\\vert \\rho_{X_i, X_j} \\vert = 1 \\leftrightarrow X_j = a X_i + b \\text{ for some } a, b \\in R \\text{, and } a \\neq 0 $ : 두 변수간의 correlation의 절대값이 1이라는 의미는 결국 두 변수간에 어떤 선형적인 관계가 형성되어 있다는 것을 의미하며, 그런 경우 분포가 가지는 randomness는 한 변수만 가지게 된다.\n",
    "- $X_i$ 와 $X_j$ 가 independent하면 $\\rho_{X_i, X_j} = 0$ 이다.\n",
    "- 위 성질의 역치는 성립하지 않는다. (i.e. $\\rho_{X_i, X_j} = 0$ 이더라도 두 변수 $X_i$와 $X_j$는 반드시 independent할 필요가 없다.)\n",
    "- 단, $(X_i, X_j)$ 가 bivariate normal distribution 이면서 $\\rho_{X_i, X_j}$가 0이라면 이때 두 변수는 indepedent하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
